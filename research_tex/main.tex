\documentclass{article}
\usepackage[left=2cm, right=5cm, top=2cm]{geometry}
\usepackage{listings}
\begin{document}
	ppshift machine learning
	
	In this document, we will be discussing methods of obtaining a credible way of classifying difficulty in VSRG maps. We will first establish what makes a map difficult, then we build from there!
	
\part{Define Difficulty}
\section{Difficulty in Playing}

	What makes a map difficult, what is a difficult map? Could it be the following?
	The map was difficult because of ...
\begin{enumerate}
	\item Failing
	\item Combo Breaks
	\item High Stamina Requirement
	\item Low Accuracy
\end{enumerate}
We discuss all of these scenarios and we will choose one to tackle, possibly integrate the other options into our calculations in the future.

\paragraph{Failing}

The most significant way that we can readily control if players fail is via \textbf{Health Drain} in which most VSRGs will implement. However, this value is inconsistent and will not provide useful information on higher \textbf{Health Drain} values due to lack of players passing certain maps.

\paragraph{Combo Breaks}

Combo Breaks analysis is another method that isn't consistent, whereby chokes can be random, creating too much noise on higher skill plays. Combo breaks mainly can only determine the \textbf{hardest} points on the map, it doesn't depict a difficulty cure.

\paragraph{High Stamina Requirements}

While stamina is a good way to look at difficulty, it can readily be derived from accuracy, which is conveniently what we'll be looking at next

\paragraph{Low Accuracy}

This is the best way to look at difficulty, because not only it gives us a figure, it tells us the story and correlation between \textbf{accuracy} and \textbf{patterning}. This will be the main focus of the document.

\section{Difficulty from Accuracy}

It is possible to measure difficulty, by just looking at accuracy, in-fact, it's quite straight-forward to do so.

Consider this...
\begin{enumerate}
	\item $Player_1$ plays $Beatmap_A$ and $Beatmap_B$
	\item $Player_1$ achieves $Accuracy_A > Accuracy_B$
	\item Considering $Accuracy_A$ and $Accuracy_B$ are independent events
	\item We deduce $Difficulty_A < Difficulty_B$
\end{enumerate}

Now, on a larger scale...
\begin{enumerate}
	\item $Player_{all}$ play $Beatmap_A$ and $Beatmap_B$
	\item $\prod_{} (Accuracy_A / Accuracy_B) > 1$
	\item Considering $Accuracy_A$ and $Accuracy_B$ are independent events
	\item We deduce $Difficulty_A < Difficulty_B$
\end{enumerate}

We can further develop this algorithm to estimate what the difficulties would be by just looking at the ratios, I won't elaborate this further as this won't be the main aim of this document because \textbf{this only works if you have scores to pivot from}. This will not work with newly developed maps.

\subsection{Replay data to actions}

In order to compare $accuracy$ and $patterning$ we need to change our perspective, instead of looking at $accuracy$ as a number, we will look at it as a vector. Whereby we extract player data from provided replays.

\subsubsection{GETting beatmap\_id data from osu!API}

Using osu!API, I was able to extract all \textbf{beatmap IDs} where $ Star Rating \leq 3.0 $ as any maps below this $Star Rating$ will usually only have \textbf{SS} scores, which will prove to be redundant in analysis.

With this list, we are able to know what maps we are tackling in the following sections.

\subsubsection{GETting Replay data from osu!API}

osu!API provides us with essential data, including the replay file itself. Not going into detail, we are able to extract all key taps (including releases) of the player during the play.

I will provide python code I have used in the GitHub Repository or in the Annex of the document.

The format we get from running the python code goes as follows

$$ action_{replay} := \lbrace(offset_1, action_1), (offset_2, action_2), ... , (offset_n, action_n)\rbrace $$

Whereby, 
$$n \in \lbrace-9, -8, ... , -2, -1, 1, 2, ... , 8, 9\rbrace$$

$offset$ is when the $action$ happens. For $action$, $-n$ means the key \textbf{n} is released, $n$ means the key \textbf{n} is pressed.

We will save this data in a file with $<beatmap\_id>.acr$ extension.

\subsection{Difficulty data to actions}

In order to make use of $Action_{replay}$, we need to obtain $Action_{difficulty}$.

\subsubsection{Downloading Difficulties through web crawling}

Using python, we can download $.osu$ (osu! difficulty file extension) using the format below with authentication:

$$https://osu.ppy.sh/osu/<beatmap\_id>$$

We save all of these using $<beatmap\_id>.osu$ file naming system.

\subsubsection{Converting Difficulties to Action format}

As to be aligned with $action_{replay}$ format, we need to convert all difficulties to $action_{difficulty}$. This can be done with a python script.

However, we should note that maps with \textbf{variable scroll speeds} will cause anomalies in our calculation, so we need to further define what maps defy a threshold we set to remove these from our calculations.

\paragraph{Scroll Speed Manipulation Threshold}
A simple way of tackling this issue would be to skip all beatmaps that has any of the following:
\begin{enumerate}
	\item Any \textbf{slight} SV Change $ 0.97 \leq TP_{SV} \leq 1.03 $
	\item Any BPM Change
\end{enumerate}

After skipping beatmaps, we will grab all remaining $.osu$ and convert them to $.acd$. The action format is the same idea, where we have a list of offset and action.

\subsection{Mapping $action_{replay}$ to $action_{difficulty}$}

This is the last essential step to find out $accuracy$ as a vector. We will match all similar actions in their respective columns together.

There are a few things we need to take note of when matching:
\begin{enumerate}
	\item Not all $action_{difficulty}$ will have a matching $action_{replay}$
	\item We put the threshold of this matching as $100ms$.
	\item The nearest $action_{replay}$ will match the $action_{difficulty}$, not the earliest one.
	\item We will deviate on how osu! calculate accuracy due to the above pointers, but its difference is insignificant.
\end{enumerate}

We will expect the output of:

$$ deviation := \lbrace(offset_1, deviation_1), (offset_2, deviation_2), ..., (offset_n, deviation_n)\rbrace $$

Where:
$$ n = length(action_{difficulty}) $$

And if there's no match, $deviation = 101$, this is to allow us to understand that it's a \textbf{miss} instead of a $100ms$ hit.

However, this is a bit ugly, so what we will use is the following:
$$ accuracy := \lbrace(offset_1, accuracy_1), (offset_2, accuracy_2), ..., (offset_n, accuracy_n)\rbrace $$

Where:
$$ accuracy_n = \frac{1}{deviation_n} $$
$$ n = length(action_{difficulty}) $$

Therefore, a \textbf{miss} would simply just be $accuracy = 0$ instead of the ugly $accuracy = 1/101$

So accuracy will only span:
$$ (Miss) 0 \leq accuracy_n \leq (Perfect) 1 $$
$$ deviation_n \in [0, 1, 2, ..., 99, 100] $$

\section{Difficulty from Patterning}

We turn our attention to how we can figure out difficulty from the map itself, the expected output we want would be:

$$ difficulty := \lbrace(offset_1, difficulty_1), (offset_2, difficulty_2), ..., (offset_n, difficulty_n)\rbrace $$

Whereby we estimate difficulty from the map itself:

$$ difficulty \approx reading + \sum_{n=1}^{keys} \left( density_n + strain_n \right) + ... $$

There are more factors (denoted by $...$) that contribute to difficulty, but we will regard them as noise in this research and fine tune this equation later.

\paragraph{Reading} This denotes how hard is it to read all the patterns on the screen. We can draw similarities between this and density, however this looks beyond note density and estimates the difficulty of reading different similar density patterns.

\paragraph{Density} This focuses on the imminent density of the offset (contrary to strain), whereby it disregards the global trends of patterns.

\paragraph{Strain} This is reliant on $density$ whereby continuous high values of $ density$ will result in a high $strain$. This has an additional hyperparameter, $decay$, where it denotes how fast the player can recover from $strain_n$. Finger $strain$ on the same hand will likely affect the other $strain$ values of the other fingers.

\subsection{Reading}

$$ reading_{(i,j)} = \frac{\sum_{i}^{j} \left( note + (longNote_{head} + longNote_{tail}) * \Gamma) \right)}{j - i}$$

Where,

\paragraph{$i$} is the initial offset
\paragraph{$j$} is the end offset
\paragraph{$\Gamma$} is the hyperparameter for how difficult a long note is to read

We will not take into consideration the length of $note_{long}$







\end{document}